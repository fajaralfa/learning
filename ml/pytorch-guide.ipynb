{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e162d2e-3e89-4e48-b331-8c82b67ffde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e32f0e-abba-4be4-9914-01217395fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress  Trouser  T-shirt/top  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e6ae91-762e-4e93-a451-de394b0b9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10cf4810-4992-4381-8af2-476d50f59308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9435, 0.8589, 0.2291, 0.0639, 0.3827, 0.6839, 0.9002, 0.0404, 0.0974,\n",
      "         0.6519],\n",
      "        [0.6999, 0.8149, 0.3013, 0.7610, 0.5581, 0.5622, 0.4275, 0.8011, 0.4968,\n",
      "         0.2771],\n",
      "        [0.3251, 0.5466, 0.5503, 0.2637, 0.5059, 0.5695, 0.1236, 0.6500, 0.8810,\n",
      "         0.8242],\n",
      "        [0.4780, 0.2098, 0.9898, 0.0840, 0.2578, 0.1410, 0.4312, 0.4860, 0.7194,\n",
      "         0.5221]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.2969279289245605\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89aa619-d944-47f8-9a36-a31ee99437a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9bf92c7-7ad8-477c-a985-59cfd3609035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a70c8c22-88bb-4978-ba37-5d06ba235f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.9693506917655468\n",
      "  batch 2000 loss: 0.9390697621870786\n",
      "  batch 3000 loss: 0.7476898397058248\n",
      "  batch 4000 loss: 0.6771027210638858\n",
      "  batch 5000 loss: 0.6122247208962217\n",
      "  batch 6000 loss: 0.5849370576590299\n",
      "  batch 7000 loss: 0.5259395990714547\n",
      "  batch 8000 loss: 0.5305815880257287\n",
      "  batch 9000 loss: 0.5096647682145121\n",
      "  batch 10000 loss: 0.46510970635607374\n",
      "  batch 11000 loss: 0.4778996824567439\n",
      "  batch 12000 loss: 0.473639328764868\n",
      "  batch 13000 loss: 0.42372484623559287\n",
      "  batch 14000 loss: 0.464842617363669\n",
      "  batch 15000 loss: 0.4453196069470723\n",
      "LOSS train 0.4453196069470723 valid 0.42516034841537476\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.42061575079109753\n",
      "  batch 2000 loss: 0.4012767502043862\n",
      "  batch 3000 loss: 0.39456646221043773\n",
      "  batch 4000 loss: 0.381171753588329\n",
      "  batch 5000 loss: 0.40279701753286645\n",
      "  batch 6000 loss: 0.4234309405551467\n",
      "  batch 7000 loss: 0.39955667639889\n",
      "  batch 8000 loss: 0.3918642314409371\n",
      "  batch 9000 loss: 0.3798001236188866\n",
      "  batch 10000 loss: 0.37289926678726626\n",
      "  batch 11000 loss: 0.3890378012509318\n",
      "  batch 12000 loss: 0.36438748288468925\n",
      "  batch 13000 loss: 0.37434780145037805\n",
      "  batch 14000 loss: 0.3616525826877332\n",
      "  batch 15000 loss: 0.37865347308351194\n",
      "LOSS train 0.37865347308351194 valid 0.3882060945034027\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.3400192392937024\n",
      "  batch 2000 loss: 0.3557410782788065\n",
      "  batch 3000 loss: 0.344724897139924\n",
      "  batch 4000 loss: 0.3632460964125348\n",
      "  batch 5000 loss: 0.3405603612171253\n",
      "  batch 6000 loss: 0.3492988164606504\n",
      "  batch 7000 loss: 0.3440894477010006\n",
      "  batch 8000 loss: 0.35093169553784537\n",
      "  batch 9000 loss: 0.28374662767200787\n",
      "  batch 10000 loss: 0.328468582327303\n",
      "  batch 11000 loss: 0.34070451702241555\n",
      "  batch 12000 loss: 0.33142601971332625\n",
      "  batch 13000 loss: 0.34241156819344903\n",
      "  batch 14000 loss: 0.3253670456327818\n",
      "  batch 15000 loss: 0.3381075790980831\n",
      "LOSS train 0.3381075790980831 valid 0.36964306235313416\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.313685908049476\n",
      "  batch 2000 loss: 0.3208464918100581\n",
      "  batch 3000 loss: 0.29861559012447836\n",
      "  batch 4000 loss: 0.3057077881267232\n",
      "  batch 5000 loss: 0.31397250824382716\n",
      "  batch 6000 loss: 0.3060657844773668\n",
      "  batch 7000 loss: 0.31043206289544834\n",
      "  batch 8000 loss: 0.31723218319000446\n",
      "  batch 9000 loss: 0.295435435376392\n",
      "  batch 10000 loss: 0.3002823394990337\n",
      "  batch 11000 loss: 0.33029078876379936\n",
      "  batch 12000 loss: 0.30521211972071616\n",
      "  batch 13000 loss: 0.3216404703275475\n",
      "  batch 14000 loss: 0.2967387471270231\n",
      "  batch 15000 loss: 0.3114336109982687\n",
      "LOSS train 0.3114336109982687 valid 0.3337514400482178\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.28997042647238414\n",
      "  batch 2000 loss: 0.27713280361362924\n",
      "  batch 3000 loss: 0.29367805471792596\n",
      "  batch 4000 loss: 0.28890957451203575\n",
      "  batch 5000 loss: 0.31554327000534976\n",
      "  batch 6000 loss: 0.2838873883688175\n",
      "  batch 7000 loss: 0.30743979279398626\n",
      "  batch 8000 loss: 0.28277743730925703\n",
      "  batch 9000 loss: 0.2835144114921568\n",
      "  batch 10000 loss: 0.2916267973888898\n",
      "  batch 11000 loss: 0.2746502241158505\n",
      "  batch 12000 loss: 0.2973259398483938\n",
      "  batch 13000 loss: 0.28319633592496396\n",
      "  batch 14000 loss: 0.28103028883921977\n",
      "  batch 15000 loss: 0.29350921481926523\n",
      "LOSS train 0.29350921481926523 valid 0.3271811902523041\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8845b090-3f7c-4b04-931b-147bff01a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for vinputs, vlabels in validation_loader:\n",
    "        voutputs = model(vinputs)\n",
    "        predicted = torch.argmax(voutputs, dim=1)\n",
    "        all_predictions.extend(predicted.tolist())\n",
    "        all_labels.extend(vlabels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae477548-d17f-465f-b082-c7f71a253ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9, 2, 1, 1, 6], [9, 2, 1, 1, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions[:5], all_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4b39d-2b1c-4e94-94bf-aa78f9da0cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
